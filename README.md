---

## ğŸš€ Google Colab Quick Start

For easy training on Google Colab, we provide ready-to-use cells in the `colab-cells/` directory.

### ğŸ“ Colab Cells Structure

```
colab-cells/
â”œâ”€â”€ 00_README.md                 # Complete instructions
â”œâ”€â”€ INDEX.md                     # Overview
â”œâ”€â”€ QUICK_REFERENCE.md           # Quick tips
â”‚
â”œâ”€â”€ Setup (3 cells)
â”‚   â”œâ”€â”€ 01_setup_environment.py
â”‚   â”œâ”€â”€ 02_install_dependencies.py
â”‚   â””â”€â”€ 03_install_preprocessing.py
â”‚
â”œâ”€â”€ Data Processing (5 cells)
â”‚   â”œâ”€â”€ 04_upload_and_prepare.py
â”‚   â”œâ”€â”€ 05_voice_separation.py
â”‚   â”œâ”€â”€ 06_segment_audio.py
â”‚   â”œâ”€â”€ 07_transcribe.py
â”‚   â””â”€â”€ 08_prepare_training_data.py
â”‚
â””â”€â”€ Training & Inference (3 cells)
    â”œâ”€â”€ 09_train_model.py
    â”œâ”€â”€ 10_test_inference.py
    â””â”€â”€ 11_gradio_interface.py
```

### âš¡ Usage Scenarios

#### Scenario 1: First Time Training (Full Pipeline)

**Time:** 3-5 hours | **GPU:** T4+ Required

```
Steps: 01 â†’ 02 â†’ 03 â†’ 04 â†’ 08 â†’ 09 â†’ 10 â†’ 11

1. Open Google Colab (colab.research.google.com)
2. Runtime â†’ Change runtime type â†’ GPU âœ…
3. Copy & run cells in order
4. Upload your audio files (Cell 04)
5. Wait for training (Cell 09: ~2-4 hours)
6. Test with Gradio UI (Cell 11)
```

**What you get:**
- Trained models saved to Google Drive
- Auto-backup checkpoints
- Web UI for generating speech
- All data preserved for reuse

---

#### Scenario 2: Inference Only (Already Have Trained Models)

**Time:** 20-30 minutes | **GPU:** Optional

**If you already trained models before and they're saved in Drive:**

```
Steps: 01 â†’ 02 â†’ 10 â†’ 11

1. Open Google Colab
2. Enable GPU (recommended)
3. Run Cell 01 (mount Drive)
4. Run Cell 02 (install F5-TTS)
5. Skip cells 03-09 âŒ (no need!)
6. Run Cell 10 (loads model from Drive)
7. Run Cell 11 (Gradio UI)
8. Generate speech! ğŸ‰
```

**Time saved:** ~90% (30 min vs 3-5 hours)

**Why it works:**
- Models are saved in: `/content/drive/MyDrive/F5TTS_Vietnamese/models/`
- Cell 10 & 11 automatically load from Drive
- No preprocessing or training needed

---

#### Scenario 3: Train Additional Speaker

**Time:** 3-4 hours | **GPU:** T4+ Required

**To train a new speaker while keeping existing ones:**

```
Steps: 01 â†’ 02 â†’ 03 â†’ 04 â†’ 08 â†’ 09 â†’ 10 â†’ 11

1. Run setup (Cells 01, 02)
2. Optional: Cell 03 (if new audio has music)
3. Upload NEW audio only (Cell 04)
4. Prepare new speaker data (Cell 08)
5. Train new speaker (Cell 09: ~2-4h)
6. Test new speaker (Cell 10)
7. Gradio UI shows ALL speakers (old + new)
```

**What happens:**
- Old models remain in Drive
- New speaker added to collection
- Cell 11 lists all available speakers
- Can switch between voices in UI

---

#### Scenario 4: Demo Only (Share with Others)

**Time:** 15-20 minutes | **GPU:** Optional

**Quick demo for presentations or sharing:**

```
Steps: 01 â†’ 02 â†’ 11

1. Run Cell 01 (mount Drive)
2. Run Cell 02 (install F5-TTS)
3. Run Cell 11 (Gradio UI with share=True)
4. Share the public link ğŸ”—
5. Anyone can use your trained voices!
```

**Perfect for:**
- Demonstrations
- Sharing with team
- Public demos
- Quick testing

---

### ğŸ“Š Time Comparison

| Scenario | Cells Needed | Time | vs First Time |
|----------|--------------|------|---------------|
| **First Time (Full)** | 01â†’11 | 3-5h | 100% |
| **Inference Only** | 01,02,10,11 | 30min | **10%** âš¡ |
| **Train New Speaker** | 01-04,08-11 | 3-4h | 70% |
| **Demo Only** | 01,02,11 | 20min | **7%** âš¡âš¡ |

---

### ğŸ’¡ Key Features

- âœ… **Virtual Environment:** Solves numpy < 2.0 compatibility issue
- âœ… **Auto-backup:** All models saved to Google Drive
- âœ… **Resume Training:** Can continue if disconnected
- âœ… **Multi-Speaker:** Train and use multiple voices
- âœ… **User-Friendly:** Step-by-step with progress bars
- âœ… **Complete Pipeline:** Voice separation, transcription, training, inference

---

### ğŸ“– Documentation

For detailed instructions, see:
- **`colab-cells/00_README.md`** - Complete guide
- **`colab-cells/INDEX.md`** - Quick overview
- **`colab-cells/QUICK_REFERENCE.md`** - Tips & troubleshooting
- **`memory-bank/`** - Full project documentation

---

### âš ï¸ Important Notes

#### Must Do Every Time:
- âœ… Enable GPU in Colab settings
- âœ… Run Cell 01 (mount Drive)
- âœ… Run Cell 02 (install F5-TTS)
- âš ï¸ Colab runtime resets each session

#### Can Skip (If Already Trained):
- âŒ Cell 03 (preprocessing tools)
- âŒ Cells 04-08 (data preparation)
- âŒ Cell 09 (training - use existing models)

#### One-Time Investment:
- Train once (3-5 hours)
- Reuse forever (20-30 min setup)
- Models persist in Google Drive
- No need to retrain!

---

## Fine-tuning pipline

Steps:

- Prepare `audio_name` and corresponding transcriptions  
- Add missing vocabulary from your dataset to the pretrained model  
- Expand the model's embedding to support the updated vocabulary  
- Perform feature extraction  
- Fine-tune the model

```bash
bash fine_tuning.sh
```

### Inference

```bash
bash infer.sh
```

### References

- Original F5-TTS repository: [https://github.com/SWivid/F5-TTS](https://github.com/SWivid/F5-TTS)
ğŸ“¦ Preparing Training Dataset...

======================================================================
ğŸ“ Organizing data structure...
======================================================================
Preparing data for 1 speaker(s): Podcast_Thuan(2)

ğŸ‘¤ Processing speaker: Podcast_Thuan(2)
   Copying 877 audio files...
   âœ… Data organized in: /content/data/Podcast_Thuan(2)_training

======================================================================
ğŸ“š Checking vocabulary...
======================================================================
   Pretrained vocab size: 2545

ğŸ‘¤ Podcast_Thuan(2):
   Dataset vocab size: 95
   Missing tokens: 18
   Missing chars: ['Ä©', 'áº©', 'áº«', 'áº³', 'áºµ', 'áº·', 'áº¹', 'á»‰', 'á»•', 'á»—', 'á»¡', 'á»£', 'á»«', 'á»­', 'á»±', 'á»³', 'á»·', 'á»¹']
   âœ… Extended vocab saved: 2563 tokens

======================================================================
ğŸ”§ Setting up vocab for prepare_csv_wavs.py...
======================================================================
âœ… Copied extended vocab to: /content/F5-TTS-Vietnamese/data/your_training_dataset/vocab.txt
   Source: /content/data/Podcast_Thuan(2)_training/vocab.txt

======================================================================
ğŸ¨ Running feature extraction...
======================================================================
â³ This may take 5-10 minutes depending on data size...

ğŸ‘¤ Processing Podcast_Thuan(2)...
   Running: prepare_csv_wavs.py
   Input/Output: /content/data/Podcast_Thuan(2)_training

Processing 877 audio files using 4 workers...

Saving to /content/data/Podcast_Thuan(2)_training ...

For Podcast_Thuan(2)_training, sample count: 877
For Podcast_Thuan(2)_training, vocab size is: 95
For Podcast_Thuan(2)_training, total 1.54 hours

   âœ… Feature extraction complete!
   raw.arrow: 0.6 MB

======================================================================
ğŸ“¥ Downloading pretrained model...
======================================================================

ğŸ‘¤ Setting up for Podcast_Thuan(2)...
   âœ… Pretrained model already exists
   ğŸ“ Need to extend embedding: +18 tokens

======================================================================
ğŸ’¾ Saving configuration...
======================================================================

ğŸ“¤ Backing up to Google Drive...
   âœ… Backed up Podcast_Thuan(2) to Drive
âœ… All data backed up to Google Drive

======================================================================
âœ… TRAINING DATA READY!
======================================================================

ğŸ“Š Preparation Summary:
   Speakers: 1
   
ğŸ‘¥ Per Speaker:


   Podcast_Thuan(2):
      Audio files: 877
      Duration: 92.3 minutes
      Vocab size: 2563
      Ready: âœ…
      
      Location: /content/data/Podcast_Thuan(2)_training
      Files:
        âœ… wavs/ (877 files)
        âœ… metadata.csv
        âœ… vocab.txt
        âœ… raw.arrow
        âœ… duration.json


ğŸ“ Next Steps:
   â†’ Run Cell 09 to start training!
   â†’ Training will take 2-4 hours for ~30 min of audio
   
âš ï¸  Before training:
   âœ… All data prepared
   âœ… Pretrained model downloaded
   âœ… Vocabulary extended
   âœ… Features extracted
   âœ… Backed up to Drive
   
ğŸ¯ Training Configuration:
   Model: F5TTS_Base (DiT, 200M params)
   Batch size: 7000 frames (adjust based on GPU)
   Epochs: 50-100 (will auto-stop if needed)
   Checkpoint: Every 10000 steps

======================================================================
ğŸ‰ Ready to train! Proceed to Cell 09!
======================================================================
# 06 - Data Requirements

## ğŸ“Š Dataset Specifications

Cháº¥t lÆ°á»£ng vÃ  quy mÃ´ dá»¯ liá»‡u quyáº¿t Ä‘á»‹nh cháº¥t lÆ°á»£ng model.

---

## ğŸ¯ Quick Reference

| Use Case | Duration | Files | Quality | Transcription |
|----------|----------|-------|---------|---------------|
| Testing | 5-10 phÃºt | 50-100 | OK | Acceptable |
| Single Voice | 1-10 giá» | 500-1000 | Good | Important |
| Good Voice Clone | 50-100 giá» | 5k-10k | High | Critical |
| Multi-Speaker | 1000+ giá» | 100k+ | High | Critical |

---

## ğŸ“ Data Format Requirements

### Audio Files

#### Format
```python
Format: WAV (recommended), MP3, FLAC
Sample Rate: 24000 Hz (24kHz)
Channels: 1 (Mono)
Bit Depth: 16-bit hoáº·c 32-bit float
```

#### Duration per File
```python
Minimum: 1 giÃ¢y
Maximum: 30 giÃ¢y
Optimal: 5-7 giÃ¢y

# Why?
- QuÃ¡ ngáº¯n (<2s): KhÃ´ng Ä‘á»§ context
- QuÃ¡ dÃ i (>15s): KhÃ³ há»c patterns
- 5-7s: Sweet spot cho TTS
```

#### Audio Quality
```python
Signal-to-Noise Ratio (SNR): >20dB
Background Noise: Minimal
Music/Sound Effects: None
Clipping/Distortion: None
Sample Rate: Consistent 24kHz
```

### Text Files

#### Format
```python
File: UTF-8 plain text (.txt)
Naming: Same as audio file
# audio_001.wav â†’ audio_001.txt
```

#### Content
```python
Language: Tiáº¿ng Viá»‡t (Vietnamese)
Casing: Lowercase recommended
Diacritics: Full Vietnamese diacritics required
Punctuation: Include (helps prosody)
Numbers: Can be digits or words
```

#### Example
```txt
# audio_001.txt
xin chÃ o cÃ¡c báº¡n, hÃ´m nay tÃ´i sáº½ nÃ³i vá» trÃ­ tuá»‡ nhÃ¢n táº¡o.

# audio_002.txt  
viá»‡t nam lÃ  má»™t Ä‘áº¥t nÆ°á»›c xinh Ä‘áº¹p vá»›i 54 dÃ¢n tá»™c anh em.
```

---

## ğŸ“ Dataset Size Guidelines

### Minimum Viable Dataset
```python
Duration: 10 phÃºt - 1 giá»
Files: 100-500 files
Purpose: Testing, proof of concept
Expected Quality: Basic, testing only
Training Time: 30 phÃºt - 2 giá»

Limitations:
- Giá»ng cÃ³ thá»ƒ khÃ´ng á»•n Ä‘á»‹nh
- PhÃ¡t Ã¢m má»™t sá»‘ tá»« sai
- Prosody khÃ´ng tá»± nhiÃªn
```

### Single Speaker Clone
```python
Duration: 5-10 giá»
Files: 500-2000 files
Purpose: Clone giá»ng cá»¥ thá»ƒ (e.g., podcast host)
Expected Quality: Good for that specific voice
Training Time: 4-12 giá»

Characteristics:
- Giá»ng á»•n Ä‘á»‹nh vá»›i speaker Ä‘Ã³
- PhÃ¡t Ã¢m chÃ­nh xÃ¡c
- Natural prosody
- CÃ³ thá»ƒ generalize cho text má»›i
```

### Production Quality (Single Voice)
```python
Duration: 50-100 giá»
Files: 5000-10000+ files
Purpose: High-quality single voice TTS
Expected Quality: Excellent
Training Time: 2-4 ngÃ y

Characteristics:
- Ráº¥t giá»‘ng giá»ng gá»‘c
- PhÃ¡t Ã¢m chuáº©n
- Natural prosody vÃ  emotion
- Robust vá»›i text má»›i
```

### Multi-Speaker System
```python
Duration: 1000+ giá»
Files: 100000+ files
Speakers: 100+ speakers
Purpose: Universal Vietnamese TTS
Expected Quality: Excellent voice cloning
Training Time: 1-2 tuáº§n

Characteristics:
- Zero-shot voice cloning
- Generalize tá»‘t cho giá»ng má»›i
- Robust vá»›i diverse texts
- Professional quality
```

---

## ğŸ¨ Data Quality Criteria

### Audio Quality Checklist

```python
âœ… Clear Speech
- Single speaker per file
- Consistent volume
- Natural speaking pace
- No overlapping speech

âœ… Clean Recording
- No background music
- No sound effects
- No noise (AC, fan, traffic)
- No echo/reverb
- No clipping/distortion

âœ… Technical Specs
- 24kHz sample rate
- Mono channel
- 16-bit or 32-bit float
- Proper normalization

âœ… Content Quality
- Complete sentences
- Natural prosody
- No heavy accent (unless desired)
- Consistent style
```

### Transcription Quality Checklist

```python
âœ… Accuracy
- 100% accurate transcription
- Every word must match audio exactly
- Include all filler words if present

âœ… Vietnamese Diacritics
- Full diacritics: Ã¡ Ã  áº£ Ã£ áº¡
- Ä (d with stroke)
- Special vowels: Äƒ Ã¢ Ãª Ã´ Æ¡ Æ°
# Wrong: xin chao
# Right: xin chÃ o

âœ… Punctuation
- Use proper punctuation
- Helps model learn prosody
- Comma, period, question mark, exclamation

âœ… Numbers & Abbreviations
- Can use digits: 123
- Or spell out: má»™t trÄƒm hai mÆ°Æ¡i ba
- Abbreviations: expand or keep (consistent)
```

---

## ğŸ—‚ï¸ Dataset Organization

### Recommended Structure

```
data/your_dataset/
â”œâ”€â”€ audio_0001.wav
â”œâ”€â”€ audio_0001.txt
â”œâ”€â”€ audio_0002.wav
â”œâ”€â”€ audio_0002.txt
â”œâ”€â”€ audio_0003.wav
â”œâ”€â”€ audio_0003.txt
â””â”€â”€ ...

# After processing â†’ becomes:
data/your_training_dataset/
â”œâ”€â”€ wavs/
â”‚   â”œâ”€â”€ audio_0001.wav
â”‚   â”œâ”€â”€ audio_0002.wav
â”‚   â””â”€â”€ ...
â”œâ”€â”€ metadata.csv
â”œâ”€â”€ vocab.txt
â”œâ”€â”€ raw.arrow
â””â”€â”€ duration.json
```

### Multi-Speaker Structure

```
data/multi_speaker/
â”œâ”€â”€ speaker_001/
â”‚   â”œâ”€â”€ audio_001.wav
â”‚   â”œâ”€â”€ audio_001.txt
â”‚   â””â”€â”€ ...
â”œâ”€â”€ speaker_002/
â”‚   â”œâ”€â”€ audio_001.wav
â”‚   â”œâ”€â”€ audio_001.txt
â”‚   â””â”€â”€ ...
â””â”€â”€ speaker_NNN/
    â””â”€â”€ ...

# Metadata includes speaker_id
speaker_001|wavs/speaker_001_audio_001.wav|xin chÃ o
speaker_002|wavs/speaker_002_audio_001.wav|hÃ´m nay trá»i Ä‘áº¹p
```

---

## ğŸ¤ Data Collection Methods

### Method 1: Professional Recording
```python
Pros:
- Highest quality
- Controlled environment
- Consistent

Cons:
- Expensive
- Time-consuming

Tools:
- Professional microphone
- Soundproof booth
- Audio interface
- DAW software
```

### Method 2: Podcast/YouTube Audio
```python
Pros:
- Large amount of data
- Natural speech
- Free/available

Cons:
- May have background music
- Need separation
- Need transcription

Pipeline:
1. Download audio
2. Music separation (Demucs)
3. Voice Activity Detection
4. Transcription (Whisper)
5. Quality filtering
```

### Method 3: Audiobook Data
```python
Pros:
- Clean audio
- Have text available
- Long duration

Cons:
- Copyright issues
- May be read-style (not natural)

Sources:
- LibriVox (public domain)
- Self-recorded
```

### Method 4: Crowdsourcing
```python
Pros:
- Scalable
- Multi-speaker data
- Cost-effective

Cons:
- Quality varies
- Need QA process

Platforms:
- Custom web interface
- Mobile app
- Recording instructions
```

---

## ğŸ” Data Filtering Guidelines

### Automatic Filtering

```python
# Duration filter
if duration < 1.0 or duration > 30.0:
    reject()

# SNR filter (if available)
if SNR < 20:
    reject()

# Text length filter
if len(text.split()) < 3:
    reject()

# Sample rate check
if sample_rate != 24000:
    resample_or_reject()

# Silence ratio
silence_ratio = detect_silence(audio)
if silence_ratio > 0.5:  # >50% silence
    reject()
```

### Manual Quality Check

```python
# Sample random files
sample_size = min(100, len(dataset) * 0.01)  # 1% or 100 files
sample_files = random.sample(all_files, sample_size)

# Check for:
for audio_file, text_file in sample_files:
    # 1. Audio quality
    âœ… Clear voice?
    âœ… No background noise?
    âœ… Proper volume?
    
    # 2. Transcription accuracy
    âœ… Text matches audio?
    âœ… Full diacritics?
    âœ… Proper punctuation?
    
    # 3. Content quality
    âœ… Natural prosody?
    âœ… Complete sentences?
    âœ… Consistent style?
```

---

## ğŸ“Š Dataset Statistics

### Key Metrics to Track

```python
# Duration distribution
Total Duration: 100.5 hours
Min Duration: 1.2s
Max Duration: 28.5s
Mean Duration: 6.3s
Median Duration: 5.8s

# File count
Total Files: 57,345
Valid Files: 56,890 (99.2%)
Rejected: 455 (0.8%)

# Vocabulary
Unique Characters: 87
Unique Words: 12,450
OOV Rate: 0.3%

# Quality metrics
Mean SNR: 28.5 dB
Files with SNR > 20dB: 98.5%
Transcription Accuracy: 99.8%
```

### Distribution Plots

```python
import matplotlib.pyplot as plt

# Duration histogram
plt.hist(durations, bins=50)
plt.xlabel("Duration (seconds)")
plt.ylabel("Count")
plt.title("Audio Duration Distribution")

# Word frequency
top_words = Counter(all_words).most_common(50)
plt.bar(words, counts)
plt.title("Top 50 Words")
```

---

## ğŸš¨ Common Data Issues

### Issue 1: Background Music
```python
Problem: Podcast cÃ³ nháº¡c ná»n

Solution:
1. Use Demucs for source separation
2. Extract vocals only
3. Quality check separated audio

Tools:
- demucs (Facebook Research)
- spleeter (Deezer)
```

### Issue 2: Multiple Speakers
```python
Problem: Conversation/interview vá»›i nhiá»u ngÆ°á»i

Solution:
1. Speaker diarization
2. Segment by speaker
3. Label speaker IDs
4. Train multi-speaker model

Tools:
- pyannote.audio
- resemblyzer
```

### Issue 3: Transcription Errors
```python
Problem: ASR khÃ´ng chÃ­nh xÃ¡c 100%

Solution:
1. Use best ASR model (Whisper large-v3)
2. Manual correction for critical data
3. Quality check randomly
4. Use confidence scores

Priority:
- High confidence â†’ auto accept
- Medium confidence â†’ review
- Low confidence â†’ manual transcribe
```

### Issue 4: Inconsistent Quality
```python
Problem: Audio quality khÃ¡c nhau giá»¯a cÃ¡c files

Solution:
1. Normalize volume across dataset
2. Apply same preprocessing
3. Filter low quality files
4. Consistent sample rate

Pipeline:
audio â†’ normalize â†’ resample â†’ denoise â†’ check_quality
```

---

## ğŸ’¡ Best Practices

### 1. Start Small, Scale Up
```python
# Phase 1: Test (1 giá»)
- Verify pipeline works
- Check quality
- Iterate quickly

# Phase 2: Expand (10 giá»)
- Scale up collection
- Refine process
- Evaluate quality

# Phase 3: Production (100+ giá»)
- Full dataset
- Final training
- Deploy model
```

### 2. Quality > Quantity
```python
10 giá» clean data > 100 giá» noisy data

Priorities:
1. Accurate transcription
2. Clean audio (no music/noise)
3. Natural speech
4. Consistent quality
```

### 3. Diverse Content
```python
âœ… DO collect:
- Different topics
- Different speaking styles
- Different sentence structures
- Various vocabulary

âŒ DON'T:
- Only one topic
- Repetitive content
- Same sentences
- Limited vocabulary
```

### 4. Version Control for Data
```python
data/
â”œâ”€â”€ v1.0/  # Initial dataset
â”œâ”€â”€ v1.1/  # Fixed transcriptions
â”œâ”€â”€ v2.0/  # Added more data
â””â”€â”€ latest â†’ v2.0

# Track changes
- CHANGELOG.md
- Data statistics
- Known issues
```

---

**Prev:** [`05-INFERENCE-PIPELINE.md`](05-INFERENCE-PIPELINE.md)  
**Next:** [`07-TECHNICAL-SPECS.md`](07-TECHNICAL-SPECS.md)




# 03 - Architecture

## ğŸ—ï¸ System Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     F5-TTS SYSTEM                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Training   â”‚      â”‚  Inference   â”‚      â”‚   API    â”‚ â”‚
â”‚  â”‚   Pipeline   â”‚      â”‚   Pipeline   â”‚      â”‚  Server  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                     â”‚                    â”‚       â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                               â”‚                            â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚                    â”‚   F5-TTS Model      â”‚                 â”‚
â”‚                    â”‚   (DiT/UNetT)       â”‚                 â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                               â”‚                            â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚                    â”‚   Vocoder (Vocos)   â”‚                 â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  Model Architecture

### F5-TTS Core Components

```python
F5-TTS Model
â”œâ”€â”€ Text Encoder
â”‚   â”œâ”€â”€ Character Embedding
â”‚   â”œâ”€â”€ Position Encoding
â”‚   â””â”€â”€ Transformer Blocks
â”‚
â”œâ”€â”€ Duration Predictor
â”‚   â””â”€â”€ Predicts phoneme durations
â”‚
â”œâ”€â”€ Flow Matching Module (CFM)
â”‚   â”œâ”€â”€ DiT (Diffusion Transformer) hoáº·c
â”‚   â””â”€â”€ UNetT (U-Net Transformer)
â”‚
â””â”€â”€ Vocoder
    â””â”€â”€ Vocos (Neural Vocoder)
```

### Detailed Architecture

#### 1. Text Encoder
```python
Input: "xin chÃ o" (text)
    â†“
Character Tokenization: ['x','i','n',' ','c','h','Ã ','o']
    â†“
Embedding Layer: [vocab_size Ã— 512]
    â†“
Positional Encoding
    â†“
Transformer Blocks: 22 layers (F5TTS_Base)
    - Dim: 1024
    - Heads: 16
    - FF Mult: 2
    â†“
Text Features: [seq_len Ã— 512]
```

#### 2. Flow Matching (CFM)
```python
Text Features + Reference Audio Embedding
    â†“
Conditional Flow Matching
    â†“
DiT Blocks (Diffusion Transformer)
    - Depth: 22 layers
    - Dim: 1024
    - Attention Heads: 16
    - Conv Layers: 4
    â†“
Mel-Spectrogram: [time Ã— 100 mel-bins]
```

#### 3. Vocoder (Vocos)
```python
Mel-Spectrogram [time Ã— 100]
    â†“
Vocos Neural Vocoder
    â†“
Waveform [sample_rate Ã— duration]
    â†“
Output: 24kHz Audio
```

---

## ğŸ“Š Model Configurations

### F5TTS_Base (Default)
```python
{
    "dim": 1024,           # Model dimension
    "depth": 22,           # Number of transformer layers
    "heads": 16,           # Attention heads
    "ff_mult": 2,          # Feed-forward multiplier
    "text_dim": 512,       # Text embedding dimension
    "conv_layers": 4,      # Convolutional layers
    "pe_attn_head": 1      # Positional encoding attention heads
}
```

### F5TTS_Small (Faster, less quality)
```python
{
    "dim": 768,
    "depth": 18,
    "heads": 12,
    "ff_mult": 2,
    "text_dim": 512,
    "conv_layers": 4
}
```

### E2TTS_Base (Alternative architecture)
```python
{
    "model_type": "UNetT",  # U-Net instead of DiT
    "dim": 1024,
    "depth": 24,
    "heads": 16,
    "ff_mult": 4
}
```

---

## ğŸ”„ Training Architecture

### Training Pipeline Flow

```
Data Loading
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dataset (metadata.csv + wavs/)    â”‚
â”‚  - Audio paths                      â”‚
â”‚  - Transcriptions                   â”‚
â”‚  - Speaker IDs (optional)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Preprocessing                 â”‚
â”‚  - Audio: Load + Resample (24kHz)  â”‚
â”‚  - Text: Tokenize                   â”‚
â”‚  - Mel-Spec: Extract features       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model Training Loop                â”‚
â”‚  1. Forward Pass                    â”‚
â”‚     - Text â†’ Text Embedding         â”‚
â”‚     - Audio â†’ Mel-Spectrogram       â”‚
â”‚     - CFM Flow Matching             â”‚
â”‚  2. Loss Calculation                â”‚
â”‚     - Flow Matching Loss            â”‚
â”‚     - Duration Loss                 â”‚
â”‚  3. Backward Pass                   â”‚
â”‚     - Gradient Computation          â”‚
â”‚     - Optimizer Step (AdamW)        â”‚
â”‚  4. EMA Update                      â”‚
â”‚     - Exponential Moving Average    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Checkpoint Saving                  â”‚
â”‚  - model_state_dict                 â”‚
â”‚  - ema_model_state_dict             â”‚
â”‚  - optimizer_state_dict             â”‚
â”‚  - training_stats                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Training Components

#### 1. CFM (Conditional Flow Matching)
```python
class CFM(nn.Module):
    """
    Conditional Flow Matching model
    """
    def __init__(self, transformer, mel_spec_kwargs, vocab_char_map):
        self.transformer = transformer  # DiT or UNetT
        self.mel_spec = MelSpec(**mel_spec_kwargs)
        self.vocab_char_map = vocab_char_map
        
    def forward(self, inp, text, duration, lens, noise_scheduler):
        # Text encoding
        text_embed = self.text_encoder(text)
        
        # Mel-spectrogram from audio
        mel = self.mel_spec(inp)
        
        # Flow matching
        z = self.transformer(mel, text_embed, duration)
        
        return loss
```

#### 2. Trainer
```python
class Trainer:
    """
    Training orchestration
    """
    def __init__(self, model, epochs, learning_rate, ...):
        self.model = model
        self.optimizer = AdamW(params, lr=learning_rate)
        self.scheduler = WarmupScheduler(...)
        
    def train(self, train_dataset):
        for epoch in epochs:
            for batch in train_loader:
                loss = self.model(batch)
                loss.backward()
                self.optimizer.step()
                self.ema_update()
```

---

## ğŸ¯ Inference Architecture

### Inference Flow

```
User Input
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Reference Audio + Text            â”‚
â”‚  - ref_audio.wav (10s)             â”‚
â”‚  - ref_text: "xin chÃ o"            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Preprocessing                     â”‚
â”‚  1. Audio â†’ Mel-Spectrogram        â”‚
â”‚  2. Text â†’ Token IDs               â”‚
â”‚  3. Extract Speaker Embedding      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Generation Text                   â”‚
â”‚  - gen_text: "tÃ´i lÃ  AI"           â”‚
â”‚  - Tokenize â†’ IDs                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  F5-TTS Model Inference            â”‚
â”‚  1. Encode gen_text                â”‚
â”‚  2. Condition on ref_audio         â”‚
â”‚  3. Flow Matching Sampling         â”‚
â”‚     - NFE steps: 32 (default)      â”‚
â”‚     - Speed control                â”‚
â”‚  4. Generate Mel-Spectrogram       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vocoder (Vocos)                   â”‚
â”‚  - Mel â†’ Waveform                  â”‚
â”‚  - Sample rate: 24kHz              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Post-Processing                   â”‚
â”‚  - Remove silence (optional)       â”‚
â”‚  - Normalize volume                â”‚
â”‚  - Save to file                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
          Output Audio
```

---

## ğŸ—‚ï¸ Code Structure

### Main Modules

```
src/f5_tts/
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cfm.py              # Conditional Flow Matching
â”‚   â”œâ”€â”€ dataset.py          # Dataset loading
â”‚   â”œâ”€â”€ trainer.py          # Training loop
â”‚   â”œâ”€â”€ modules.py          # Building blocks
â”‚   â”œâ”€â”€ utils.py            # Utilities
â”‚   â””â”€â”€ backbones/
â”‚       â”œâ”€â”€ dit.py          # DiT architecture
â”‚       â”œâ”€â”€ mmdit.py        # MM-DiT architecture
â”‚       â””â”€â”€ unett.py        # UNetT architecture
â”‚
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ finetune_cli.py     # Training CLI
â”‚   â”œâ”€â”€ finetune_gradio.py  # Training UI
â”‚   â”œâ”€â”€ train.py            # Core training
â”‚   â””â”€â”€ datasets/
â”‚       â””â”€â”€ prepare_csv_wavs.py  # Data preparation
â”‚
â””â”€â”€ infer/
    â”œâ”€â”€ infer_cli.py        # Inference CLI
    â”œâ”€â”€ infer_gradio.py     # Inference UI
    â””â”€â”€ utils_infer.py      # Inference utilities
```

### Class Hierarchy

```python
# Model
CFM
â”œâ”€â”€ transformer: DiT | UNetT | MMDiT
â”œâ”€â”€ mel_spec: MelSpec
â””â”€â”€ vocab_char_map: dict

# Trainer
Trainer
â”œâ”€â”€ model: CFM
â”œâ”€â”€ optimizer: AdamW
â”œâ”€â”€ scheduler: WarmupScheduler
â””â”€â”€ ema_model: ExponentialMovingAverage

# Dataset
load_dataset()
â”œâ”€â”€ metadata.csv â†’ audio_path, text pairs
â”œâ”€â”€ wavs/ â†’ audio files
â””â”€â”€ vocab.txt â†’ character vocabulary
```

---

## ğŸ” Key Design Patterns

### 1. EMA (Exponential Moving Average)
```python
# Duy trÃ¬ shadow weights cho stable inference
ema_model = EMA(model, beta=0.9999)

# Training
for batch in data:
    loss = model(batch)
    loss.backward()
    optimizer.step()
    ema_model.update()  # Update shadow weights

# Inference - sá»­ dá»¥ng EMA weights
with ema_model.average_parameters():
    output = model(input)
```

### 2. Flow Matching
```python
# Thay vÃ¬ diffusion steps, dÃ¹ng continuous flow
t = random.uniform(0, 1)  # Flow time
z_t = t * data + (1 - t) * noise
velocity = model(z_t, t, condition)
loss = ||velocity - (data - noise)||Â²
```

### 3. Character-based Tokenization
```python
# KhÃ´ng dÃ¹ng phoneme, dÃ¹ng trá»±c tiáº¿p characters
text = "xin chÃ o"
tokens = [vocab[c] for c in text]
# â†’ ['x','i','n',' ','c','h','Ã ','o']
```

---

## ğŸ“ˆ Memory & Compute Requirements

### Training

| Batch Size (frames) | GPU Memory | Speed (steps/s) |
|---------------------|------------|-----------------|
| 3200                | 8GB        | 0.5             |
| 7000                | 16GB       | 0.8             |
| 10000               | 24GB       | 1.0             |

### Inference

| Duration | GPU Memory | Time (T4) | Time (CPU) |
|----------|------------|-----------|------------|
| 5s       | 2GB        | 2s        | 10s        |
| 10s      | 2GB        | 3s        | 15s        |
| 30s      | 3GB        | 8s        | 40s        |

---

**Prev:** [`02-QUICK-START.md`](02-QUICK-START.md)  
**Next:** [`04-TRAINING-PIPELINE.md`](04-TRAINING-PIPELINE.md)



